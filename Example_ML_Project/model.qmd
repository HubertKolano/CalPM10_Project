---
title: "NORM AQMD"
subtitle: "Meteorological normalization of air quality monitoring system data (Part 2A)" 
author: "Mateusz Rzeszutek"
date: today
format: 
  html:
    self-contained: true
    toc: true
    toc-depth: 4
    toc-location: right
    toc-title: "Spis treści"
    number-sections: true
    number-depth: 4
    code-fold: show
    code-summary: "Show the code"
    code-tools: true
    code-block-bg: true
    code-block-border-left: "black"
    code-line-numbers: false
    code-copy: true
    smooth-scroll: true
    anchor-sections: true
    link-external-icon: true
    link-external-newwindow: true
    theme:
        light: cosmo
        dark: darkly
    fontsize: 1.0em
    linestretch: 1.5
    fig-align: center
    fig-height: 10
    fig-width: 8
    mermaid-format: svg
editor: 
  markdown: 
    wrap: 72
execute:
  warning: false
  echo: true
  error: false
  cache: false
editor_options: 
  chunk_output_type: inline
---
## Pakiety

```{r}
library(tidymodels)
library(tidyverse)
library(stringr)
library(vip)
library(pdp)
library(DALEX)
library(DALEXtra)
library(bestNormalize)
library(rules)
library(baguette)
library(finetune)
library(doParallel)

tidymodels_prefer()
```

## Funkcja

```{r}
source("model_test/function_wd_factor.R")
```

## Read

```{r}
load("bujaka_aqm.rdata")
load("dane_imgw.rdata")
load("era.rdata")
```

## 

```{r}
bujaka <- 
  bujaka |> openair::selectByDate(year = 2011:2022) |> 
  rename(pm10 = obs)


era <- era |> 
  mutate(date = date + 3600) |> 
  filter(lat == 50.0, lon == 20.0) |> 
  select(date, blh, ssrd)

dane_imgw <- 
  dane_imgw |> 
  mutate(date = date + 3600) |> 
  select(date, ws, wd, tt, rh, pres, tskc)

bujaka <-
  bujaka |>
  left_join(dane_imgw, by = "date") |>
  left_join(era, by = "date") |> 
  select(date, pm10, blh, ws:tskc, ssrd)

rm(dane_imgw, era)
```

Eksport danych

```{r}
bujaka |> 
  ggplot(aes(ssrd)) +
  geom_histogram()

bujaka |> 
  mutate(ssrd = if_else(ssrd < 0, 0.0, ssrd)) |> 
  rename(conc = pm10) |> 
  write.csv(file = "dane_ote_example_1_bujaka.csv", row.names = F)

bujaka |> summary()
bujaka |> glimpse()
```


**UWAGA** W całym skrypcie PM10 trzeba zaminic na nazwę universalną `conc`.

## Dodatkowe zmienne

```{r}
Sys.setlocale(locale = "english")

bujaka <- 
  bujaka |> as_tibble() |> 
  janitor::clean_names() |> 
  mutate(jday = lubridate::yday(date)) |>
  mutate(
    wday = lubridate::wday(x = date, abbr = T, label = T),
    hour = lubridate::hour(x = date),
    day_work = case_when(
      wday == "Mon" ~ "week",
      wday == "Tue" ~ "week",
      wday == "Wed" ~ "week",
      wday == "Thu" ~ "week",
      wday == "Fri" ~ "week",
      wday == "Sat" ~ "weekend",
      wday == "Sun" ~ "weekend"
    )
  ) |> 
  mutate(day_work = as.factor(day_work))

bujaka <- 
  bujaka |> 
  na.omit() |> 
  wd_factor(wd, name = "short")

bujaka <-
  bujaka |>
  mutate(trend = date |> as.numeric()) |>
  select(-date)

# bujaka <- bujaka[1:1000,] # do testów wstępnych, czy działa, tak jak trzeba kod.
```

## Formuła ----

```{r}
forms <- formula(pm10 ~ .)
```

## Podział danych ----

### Podstawowy ----

```{r}
air_split <- initial_validation_split(data = bujaka, strata = pm10)

air_train <- training(air_split)
air_test  <- testing(air_split)
air_valiid <- validation_set(air_split)

air_vold <- vfold_cv(air_train, strata = pm10, v = 10, repeats = 5) # testowo
```

## MODEL 

```{r}
cart_spec <-
  decision_tree(cost_complexity = tune(),
                min_n = tune()) %>%
  set_engine("rpart") %>%
  set_mode("regression")

rf_spec <- 
  rand_forest(mtry = tune(), 
              min_n = tune(), 
              trees = 200) |> 
  set_engine("ranger") |> 
  set_mode("regression")

cubist_spec <-
  cubist_rules(committees = tune(), 
               neighbors = tune()) %>%
  set_engine("Cubist") |> 
  set_mode("regression")

xgb_spec <-
  boost_tree(
    tree_depth = tune(),
    learn_rate = tune(),
    loss_reduction = tune(),
    min_n = tune(),
    sample_size = tune(),
    trees = 600,
  ) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

basic_rec <-
  recipe(pm10 ~ ., data = air_train) |> 
  update_role(wd, wday, new_role = "ID") 

basic_t_rec <-
  recipe(pm10 ~ ., data = air_train) |> 
  update_role(wd, wday, new_role = "ID") |> 
  step_dummy(all_nominal_predictors()) |> 
  step_zv(all_nominal_predictors())

prep(basic_t_rec, training = air_train) |> juice() 

prep(basic_rec, training = air_train) |> juice()

summary(basic_rec) |> knitr::kable()

```

## Workflow

```{r}
a <-
  workflow_set(
    preproc = list(b    = basic_rec),
    models  = list(
      ranger   = rf_spec,
      cubist   = cubist_spec,
      rpart    = cart_spec
    )
  )
b <-
  workflow_set(preproc = list(t       = basic_t_rec),
               models  = list(xgboost = xgb_spec))

basic <- bind_rows(a, b)

basic$wflow_id <- str_sub(basic$wflow_id, start = 3, end = 100)
basic
```

## set parameters dials

```{r}
cart_param <-
  cart_spec %>%
  extract_parameter_set_dials() %>%
    update(min_n = min_n(c(8,20)))

rf_param <-
  rf_spec %>%
  extract_parameter_set_dials() %>%
  update(min_n = min_n(c(8,20)), mtry =  mtry(c(3,10)))

xgb_param <-
  xgb_spec %>%
  extract_parameter_set_dials() %>%
    update(min_n = min_n(c(8,20)))

basic <- basic |> option_add(param_info = cart_param, id = "rpart")
basic <- basic |> option_add(param_info = rf_param, id = "ranger")
basic <- basic |> option_add(param_info = xgb_param, id = "xgboost")
```


## GRID COTROL and GRID HIPERPARAMETERS

```{r}
# gdy nie stosuje race, czyli skrócenia czasu obliczeń. 
grid_ctrl <-
  control_grid(
    save_pred = TRUE,
    parallel_over = "everything",
    save_workflow = TRUE
  )

# gdy stosuje tune_race_anova
race_ctrl <-
   control_race(
      save_pred = TRUE,
      parallel_over = "everything",
      save_workflow = FALSE
   )
# dla finetune 15.4
```

## Tune many models

```{r}
#| eval: false
#| include: true
#| label: Trening wielu modeli równolegle z zastosowaniem anova (redukcja czasu obl.),  

cores <- parallel::detectCores(logical = FALSE)
cl <- makePSOCKcluster(cores)
registerDoParallel(cl)

time <- Sys.time()
   
      basic  |>        # 1:4 bo tylko wariant b, t został dla przykładu
      workflow_map(
        "tune_race_anova",
        seed = 1503,
        resamples = air_vold,
        grid = 100,
        control = race_ctrl,
        verbose = TRUE,
        metrics = metric_set(rmse, rsq, mae)
      )

results_time <-
  system.time(tune_result)

stopCluster(cl)

Sys.time() - time

save(tune_result, file = "./tune_result.Rdata")
```


## RESULT

```{r}
load("tune_result.Rdata")
tune_result |> collect_metrics()
```


```{r}
autoplot(
  tune_result,
  rank_metric = "rmse",
  # <- how to order models
  metric = "rmse",
  # <- which metric to visualize
  select_best = TRUE     # <- one point per workflow
) +
  geom_text(aes(y = mean - 3, label = wflow_id),
            angle = 90,
            hjust = 1) +
  ylim(15, 50)

autoplot(
   tune_result,
   rank_metric = "mae",  # <- how to order models
   metric = "mae",       # <- which metric to visualize
   select_best = TRUE     # <- one point per workflow
) +
  geom_text(aes(y = mean - 1, label = wflow_id),
            angle = 90,
            hjust = 1) +
  ylim(10, 30)

autoplot(
   tune_result,
   rank_metric = "rsq",  # <- how to order models
   metric = "rsq",       # <- which metric to visualize
   select_best = TRUE     # <- one point per workflow
) +
   geom_text(aes(y = mean - 1/18, label = wflow_id), angle = 90, hjust = 1) +
  ylim(0.5, 1)
```


```{r}
autoplot(tune_result, id = "cubist", metric = "rsq")
```


```{r}
library(tidyverse)

tune_result |>  
  rank_results() |>
  mutate(wflow_id = fct_reorder(wflow_id, rank)) |> 
  ggplot(aes(wflow_id, mean, colour = wflow_id)) +
  geom_point() +
  geom_errorbar(aes(ymin = mean - std_err,
                    ymax = mean + std_err), width = 0.4) +
  facet_wrap(~.metric, scales = "free_y") +
  theme_bw() + 
  labs(x = "Model", 
       y = "Wartość metryki", 
       colour = "Model") -> p ; p


ggsave(filename = "rys. 3._valid_result_model.jpeg", device = "jpeg", 
       width = 8.5, height = 3, dpi = 300)
```


```{r}
tune_result |> 
  extract_workflow_set_result(tune_result, id = "ranger") |> 
  _$.metrics |> _[[1]] |>
  filter(.metric == "rsq") |> 
  ggplot(aes(min_n, .estimate)) +
  geom_point() +
  facet_grid(~mtry)

tune_result |> extract_workflow_set_result(tune_result, id = "rpart") |> _$.metrics |> _[[1]] 
tune_result |> extract_workflow_set_result(tune_result, id = "ranger") |> _$.metrics |> _[[1]]   
tune_result |> extract_workflow_set_result(tune_result, id = "cubist") |> _$.metrics |> _[[1]] 
tune_result |> extract_workflow_set_result(tune_result, id = "xgboost") |> _$.metrics |> _[[1]] 

```


```{r}

c("ranger", "rpart", "cubist", "xgboost") |>
  map_dfr(
    ~ tune_result |>
      extract_workflow_set_result(tune_result, id = .x) |>
      show_best(metric = "rmse", n =5) |> mutate(new = .x)
  ) |>
  knitr::kable(digits = 2)


c("rsq", "mae", "rmse") |>
  map_dfr(
    ~ tune_result |>
      extract_workflow_set_result(tune_result, id = "ranger") |>
      show_best(metric = .x, n =5)
  ) |>
  knitr::kable(digits = 2)

c("rsq", "mae", "rmse") |>
  map_dfr(
    ~ tune_result |>
      extract_workflow_set_result(tune_result, id = "cubist") |>
      show_best(metric = .x, n =5)
  ) |>
  knitr::kable(digits = 2)


c("rsq", "mae", "rmse") |>
  map_dfr(
    ~ tune_result |>
      extract_workflow_set_result(tune_result, id = "rpart") |>
      show_best(metric = .x, n =5)
  ) |>
  knitr::kable(digits = 10)

c("rsq", "mae", "rmse") |>
  map_dfr(
    ~ tune_result |>
      extract_workflow_set_result(tune_result, id = "xgboost") |>
      show_best(metric = .x, n =5)
  ) |>
  knitr::kable(digits = 4)
```


## SELECT BEST MODELS ALL

```{r}
#| eval: false
#| include: true

modele <- tune_result$wflow_id

best_results <-
  modele  |> 
  map( ~ extract_workflow_set_result(tune_result, id = .x) %>%
         select_best(metric = "rmse"))

best_results |> knitr::kable()

names(best_results) <- modele

best_models <-
  modele %>%
  map(
    ~ extract_workflow(tune_result, id = .x) %>%
      finalize_workflow(best_results[[.x]]) %>%
      last_fit(split = air_split)
  )

names(best_models) <- modele

save(best_models, file = "best_models.rdata")
```

## RESULT BEST MODELS

```{r}
load(file = "best_models.rdata")
```



```{r}
names(best_models)

names(best_models) %>% 
      map_dfr(~collect_metrics(best_models[[.x]]) %>% 
                mutate(mod = .x)) |> 
  mutate(mod = factor(mod, levels = c("rpart", "ranger", "cubist", "xgboost"))) |> 
  ggplot(aes(mod, .estimate, colour = mod)) +
  geom_point() +
  facet_wrap(~.metric, scales = "free_y") +
  theme_bw() + 
  labs(x = "Model", 
       y = "Wartość metryki", 
       colour = "Model") -> p ; p

ggsave(filename = "rys_4_test_result_model.jpeg", device = "jpeg", 
       width = 8.5, height = 3, dpi = 300)

por_test_valid <- 
bind_rows(
  names(best_models) |>
    map_dfr( ~ collect_metrics(best_models[[.x]]) |>
               mutate(mod = .x)) |>
    select(mod, .metric, .estimate) |>
    rename(mean = .estimate) |>
    mutate(typ = "walidacyjny"),
  tune_result |>
    rank_results() |>
    select(wflow_id, .metric, mean) |>
    rename(mod = wflow_id) |>
    mutate(typ = "testowy")
) |>
  mutate(mod = factor(mod, 
                      levels = c("rpart", "ranger", "cubist", "xgboost"))) |> 
  pivot_wider(names_from = typ, 
              values_from = mean) |> 
  filter(.metric != "mae") 

por_test_valid |> 
  ggplot(aes(walidacyjny, testowy, colour = mod)) +
  geom_point() + 
  facet_wrap(~.metric, scales = "free") +
  theme_bw() + 
  geom_abline(slope = 1) +
  labs(x = "Wartość metryki (walidacyjny)", 
       y = "Wartość metryki (testowy)", 
       colour = "Model") -> p ; p

ggsave(filename = "rys_5_test_result_model.jpeg", device = "jpeg", 
       width = 8.5, height = 3, dpi = 300)
```



```{r}
best_models$ranger |> augment()

  modele |>
  map_dfr(~ augment(best_models[[.x]]) |>
            mutate(mod = .x)) |>
  ggplot(aes(pm10, .pred)) +
  geom_point() +
  facet_wrap(~mod) +
  geom_abline(slope = rep(c(1.5, 0.5, 1), 4)) +
  theme_bw() +
  labs(title = "Best models for test data") +
  scale_x_continuous(expand = c(0,0), limits = c(0, 510)) +
  scale_y_continuous(expand = c(0,0), limits = c(0, 510)) +
  coord_obs_pred() +

  theme(plot.title = element_text(hjust = 0.5)) +
  labs(
    x =  expression("Concentration PM"[10] *
                      " [" * mu * "g m" ^ -3 * "] - Observation") ,
    y = expression("Concentration PM"[10] *
                     " [" * mu * "g m" ^ -3 * "] - Predicted")
  ) 

ggsave(
  filename = "fig_2_Best_models_for_test_data.jpeg",
  device = "jpeg",
  width = 8.00,
  height = 4.60,
  dpi = 300
)

modele |>
  map_dfr(~ augment(best_models[[.x]]) |>
            mutate(mod = .x)) |> 
  openair::modStats(mod = ".pred", obs = "pm10", type = "mod") |> 
  arrange(FAC2)

```


***
## EXPLAIN MODEL

***

**PREDICTOR**

```{r}
# zobacz w tym obiekcie, czy można wyciągać z niego po kolei przepis i zobaczyć i wyeksportować przepisy dla każdego modelu, ważne bo każda kombinacja ma inne predyktory. 
modele <- names(best_models)

many_predictor <-
  modele |> 
  map(
    ~ extract_recipe(best_models[[.x]]) |> 
      summary() %>%
      filter(role == "predictor") |> 
      pull(variable)
  )

names(many_predictor) <- names(best_models)
```



**Explain**

```{r}
explain_models <-
  modele %>%
  purrr::map(
    ~ explain_tidymodels(
      model = best_models[[.x]]$.workflow[[1]],  # select fit
      data = dplyr::select(air_train, -pm10),
      y = air_train$pm10,
      variables = many_predictor[[.x]],
      label = .x,
      verbose = FALSE
    )
  )

names(explain_models) <- names(best_models)

save(explain_models,
     tune_result,
     best_models,
     file = "for_pdp.rdata")
```


***
### Importance variable

***

Główną ideą jest zmierzenie, jak bardzo zmieni się wydajność modelu, jeśli
zostanie usunięty wpływ wybranej zmiennej objaśniającej lub grupy zmiennych? Aby
usunąć efekt, używamy perturbacji, takich jak ponowne próbkowanie z rozkładu
empirycznego lub permutacja wartości zmiennej. Im większa zmiana wydajności, tym
ważniejsza jest zmienna.

Na przykład, jeśli zmienne są skorelowane, oczekuje się, że modele, takie jak random forest, rozłożą wpływ na wiele zmiennych, podczas gdy w modelach regresji uregulowanej wpływ jednej zmiennej może zdominować wpływ innych skorelowanych zmiennych. 

```{r}
load("for_pdp.rdata")
```

**Obliczenia**

```{r eval=FALSE, include=T}
# 30 minu 80 model 

names(explain_models) 

importance_models <-
  names(explain_models) %>%
  map_dfr(~ model_parts(explainer = explain_models[[.x]],
                    loss_function = loss_root_mean_square)) 

save(importance_models, file = "importance_models.rdata")
```

```{r}
load("importance_models.rdata")
```

**Wykres całkowiej efektywności modelu `L`**

L - to funkcja straty wzynaczona dla całego modelu, przy zachowaniu orginalnych
danych i predyktorów.

```{r, wykres jakość modeli RMSE (importance)}

# Ogólna ważność modelu. Im mniej tym lepiej . 

importance_models %>% 
  as_tibble() %>% 
  filter(variable == "_full_model_") %>%
  mutate(label = forcats::fct_reorder(label, dropout_loss)) %>%
  mutate(mod = str_split_fixed(label, "_", 2)[, 2],
         n   = str_split_fixed(label, "_", 2)[, 1]) %>%
  ggplot(aes(x   = n,
             y   = dropout_loss,
             col = n)) +
  geom_point(size = 2) +
  theme_bw() +
  labs(y = "RMSE", # Root mean square error (RMSE) after permutations
       x = "Model")
```

**Każdy model osobno**

```{r}

out <- tibble()
z <- importance_models %>% as_tibble() 

for (i in unique(z$label)) {
  
  inp <- 
    z %>% 
    filter(label == i)
  
  war <- 
    inp %>% 
    filter(variable == "_full_model_") %>%
    select(dropout_loss) %>% 
    pull() %>% 
    .[1]
  
  inp <- 
    inp %>%
    mutate(dropout_loss = if_else(dropout_loss == war,
                                  NaN,
                                  dropout_loss)) %>% 
    na.omit()
  
  out <- bind_rows(out, inp)
  
}

out <- 
  out %>% 
  filter(variable != "_baseline_") %>% 
  group_by(variable, label) %>% 
  summarise(mean = mean(dropout_loss)) %>% 
  ungroup()
  
out <- 
  out %>% 
  mutate(mod = str_split_fixed(label, "_", 2)[, 2],
         n   = str_split_fixed(label, "_", 2)[, 1]) 

out |> 
  filter(n %in% c("cubist", "xgboost")) |> 
  knitr::kable()

out |> 
  filter(variable == "day_work") |> 
  knitr::kable()

out |> 
  filter(variable == "trend") |> 
  knitr::kable()



for (i in out$n %>% unique()) {
  out %>% filter(n == i) %>%
    ggplot(aes(mean,
               factor(variable),
               fill = variable)) +
    geom_col(position = "dodge") +
    facet_wrap(vars(mod), scale = "free") +
    theme_bw() +
    theme(legend.position = "none") +
    labs(
      x = "RMSE",
      y = "Zmienna objasniająca",
      fill = NULL,
      color = NULL
      ) -> p
  print(p)
  ggsave(filename = paste0("rys_x_", i, ".jpeg"), 
         plot = p, 
         device = "jpeg", width = 7, height = 5, dpi = 300)
}

```

### PD LD AL  

Uwaga !!! Podwójna pętla wenetrzna map_dfr - wykorzystuje nazwy zmiennych w celu
objasnienia każdej. Wyjście to obiekt listy zwierajcy tabele tiblle
przechowujące informacje o wartosciach PDP.


**AL**

Jeśli zmienna objaśniająca jest skorelowana z niektórymi innymi zmiennymi, profil LD dla tej zmiennej nadal będzie uwzględniał wpływ innych zmiennych. Dzieje się tak dlatego, że profil uzyskuje się poprzez marginalizację (w rzeczywistości ignorowanie) pozostałych zmiennych w modelu, co daje efekt podobny do błędu „pominiętej zmiennej” w regresji liniowej. Pod tym względem profile LD mają to samo ograniczenie co profile PD. Aby rozwiązać ten problem, Apley i Zhu ( 2020 ) zaproponowali koncepcję efektów lokalnej zależności i skumulowanych profili lokalnych (AL).


Jak argumentują Apley i Zhu ( 2020 ) , uśrednianie efektów lokalnych pozwala uniknąć występującego w profilach PD i LD problemu uchwycenia wpływu innych zmiennych w profilu dla danej zmiennej w modelach addytywnych (bez interakcji)

Gdy zmienne objaśniające są niezależne i nie ma interakcji w modelu, profile CP są równoległe, a ich średnia, tj. profil PD wprowadzony w rozdziale 17 , odpowiednio je podsumowuje.

Gdy model jest addytywny, ale zmienna objaśniająca jest skorelowana z niektórymi innymi zmiennymi, ani profile PD, ani LD nie będą właściwie ujmować wpływu zmiennej objaśniającej na predykcje modelu. Jednak profil AL zapewni prawidłowe podsumowanie efektu.

Gdy w modelu występują interakcje, żaden z profili nie zapewni prawidłowej oceny wpływu jakiejkolwiek zmiennej objaśniającej związanej z interakcją(ami). Dzieje się tak, ponieważ profile zmiennej będą uwzględniać również wpływ innych zmiennych. Porównanie profili PD, LD i AL może pomóc w określeniu, czy w modelu występują jakiekolwiek interakcje i/lub czy zmienne objaśniające są skorelowane. Gdy występują interakcje, można je zbadać za pomocą uogólnienia profili PD dla dwóch lub więcej zmiennych zależnych (Apley i Zhu 2020 ).

**FUNKCJA** Liczy jednocześnie `PD`, `PC`, `AL` dla każdego warianru, który jest wektorem.

```{r}
mod_prof_all_typ <- function(input_model, predictor) {

  c("partial", "conditional",  "accumulated") %>%
    purrr::map_dfr(
      ~ model_profile(
        explainer = input_model,
        variables = predictor,
        N = NULL,
        type = .x
      ) %>%
        .$agr_profiles %>%
        as_tibble() %>%
        mutate(type = .x)
    )
}
```

Zastosowanie funkcji.

```{r, eval=F, include=TRUE}
# select names
id_t <- names(explain_models)[explain_models |> 
                                names() %>%
                                str_detect("t_",
                                           negate = T)]
# select names in list
explain_models <- explain_models[id_t]
many_predictor <- many_predictor[id_t]

# check
explain_models %>% length()
many_predictor %>% length()

# profile variables
n <- Sys.time()
pd_ld_al <- 
names(explain_models) %>% 
  map_dfr( ~ mod_prof_all_typ(input_model = explain_models[[.x]], 
                              predictor = many_predictor[[1]])) # ten sam nie liczymy osobno dla każdej zmiennej
nn <- Sys.time() - n
nn

save(pd_ld_al, file = "profiles_all.rdata")
```

```{r}
load("profiles_all.rdata")
```


Tworzymy funkcje kreślenia i zapisywania wykresów. 


```{r}
pd_ld_al %>%
  filter(type != "conditional") %>%
  group_by(`_label_`, `_vname_`) %>%
  summarise(
    min = min(`_yhat_`),
    max = max(`_yhat_`),
    x_min = min(`_x_`)
  ) %>%
  mutate(diff = max - min) -> pd_sum

test <-
  pd_ld_al  |>
  filter(type != "conditional") |>
  group_split(`_label_`)

pd_ld_al$`_vname_` |> unique()
test[[1]]$`_vname_` |> unique()

pd_ld_al %>%
  filter(type != "conditional") %>%
  group_split(`_label_`) %>%
  purrr::map(
    ~ ggsave(
      paste0("XPDP/", 
             str_split_fixed(first(.$`_label_`), "_", 2)[2],
             "_",
             str_split_fixed(first(.$`_label_`), "_", 2)[1],
             ".jpeg"),
      device = "jpeg",
      width = 11,
      height = 8,
      dpi = 300,
      ggplot(., aes(
        x = `_x_`,
        y = `_yhat_`,
        color = type,
        group = type
      )) +
        geom_line(size = 1.2,
                  alpha = 0.8) +
        facet_wrap(vars(`_vname_`),
                   ncol = 4,
                   scales = "free") +
        theme_bw() +
        theme(legend.position = "bottom", 
              legend.direction = "horizontal") +
        labs(
          x = "Wartość zmienne objaśniającej",
          y = expression(
            "Prognozowane stężenie PM10 [" * mu * "g/m" ^ -{3} * "]"
          ),
          color = NULL
        )
    )
  )

```

***

### PDP RESULT

***

```{r}
dir("XPDP/")
```



```{r}
knitr::include_graphics("XPDP/_rpart.jpeg")
knitr::include_graphics("XPDP/_ranger.jpeg")
knitr::include_graphics("XPDP/_cubist.jpeg")
knitr::include_graphics("XPDP/_xgboost.jpeg")
```

***

## NORMALIZATION

### Model fit 

Buduję model na całym zestawie danych

```{r}
modele <- tune_result$wflow_id

best_results <-
  modele  |>
  map(~ extract_workflow_set_result(tune_result, id = .x) %>%
        select_best(metric = "rmse"))


names(best_results) <- modele

norm_model <-
  modele %>%
  map(
    ~ extract_workflow(tune_result, id = .x) %>%
      finalize_workflow(best_results[[.x]]) %>%
      fit(bujaka)
  )

names(norm_model) <- modele

save(norm_model, file = "norm_model.rdata")
```

```{r}
bujaka      # zestaw danych oryginalnych do podziału
best_models # modele best
```

```{r}
vars <-                         # wektor predyktorów z recipe
  basic_rec |>
  summary() |>
  filter(role == "predictor") |>
  pull(variable)

# Wybiera wrzystkie po za drygim argumentem

vars_trend <- setdiff(vars,        # wszystkie predyktory
                      c("trend"))  # wskazujemy te, które chcemy przeanalizować
```


------------------------------------------------------------------------

## Fun Sample

------------------------------------------------------------------------


Prosta funkcja. Wybiera zmienne którym chcemy się przyjrzeć. Przy założeniu, że posotałe zostaną uśrednione. Jak to się dzieje ? Pozostałe predyktory przyporządkowuje losowo. Tylko w zakresie istniejącego zestawu danych. Ta funkcja tworzy jeden taki zestaw danych.

Następna funkcja powiela tą operację `n` - razy.

```{r}
# Funkcja sample select date
randomly_sample_meteorology <- function(list_model, df, variables) {
  
  tidymodels_prefer()
  
  # Randomly sample observations
  index_rows <- sample(1:nrow(df), replace = FALSE)
  
  # Transform data frame to include sampled variables
  df[variables] <- lapply(df[variables], function(x) x[index_rows])
  
  .pred <- predict(list_model, df, type = "numeric")$.pred
  
  # Use models to predict and Build data
  df <- df %>% mutate(.pred = .pred)
  
  return(df)
  
}

# Test funkcji
randomly_sample_meteorology(list_model = norm_model[["rpart"]],
                            df =  bujaka[1:100,],
                            variables = setdiff(vars, c("trend"))) # pomiń trend
```

------------------------------------------------------------------------

## Function parallel

------------------------------------------------------------------------

Skoro powielamy n-razy. To najlepiej rónolegle. Pojawiają się problemy z eksportem funkcji z zmiennych globalnych :(

```{r}
# UWAGA MUSI BYĆ KOLUMNA date - nie była definiowana
library(foreach)
norm_air <- function(list_model = fit,
                     # see example,
                     df =  d_air,
                     variables = setdiff(vars, c("trend")),
                     n =  200,
                     core = 10) {
  
  # if (sum(colnames(df) %in% c("date")) != 1) {
  #   stop("Brakuje kolumny `date` w obiekcie df")
  # }
  
  cl <- parallel::makeCluster(core)
  doParallel::registerDoParallel(cl)
  
  out <- df
  
  df <- foreach(
    i = 1:n,
    .inorder = FALSE,
    .combine = "rbind",
    .packages = c("tidymodels"),
    .export = c(
      "randomly_sample_meteorology",
      "predict",
      "tidymodels_prefer"
    )
  ) %dopar%
    randomly_sample_meteorology(list_model,
                                df,
                                variables)
  
  parallel::stopCluster(cl)
  
  df <- group_by(df, trend) %>%
    summarise(.pred = mean(.pred, na.rm = TRUE)) %>%
    ungroup() %>%
    as_tibble()
  
  out <- left_join(out, df, by = "trend")
  
  return(out)
}
```


------------------------------------------------------------------------

## Computation

------------------------------------------------------------------------

Wykonano przy założeniu, że dwie zmienne definiują oddziływanie transportu drogowego na jakość powietrza.

```{r, eval=F, include=T}
#| label: Normalizacja

norm_data <-
  modele %>%
  map_dfr(
    ~  norm_air(
      list_model = norm_model[[.x]],
      df =  bujaka,
      variables = setdiff(vars, c("trend")),
      n =  200,
      core = 10
    ) %>%
      mutate(.mod = .x)
  )

save(norm_data, file = "norm_data.rdata")
```

```{r}
load("norm_data.rdata")
```

```{r}
trend_data <-
  norm_data |>
  mutate(date = as.POSIXct(trend), .before = "pm10") |>
  openair::TheilSen(
    pollutant = ".pred",
    type = ".mod",
    avg.time = "month",
    layout = c(2, 2), xlab = "rok", ylab = "Stężenie PM10 ug/m3"
  )

trend_data$data$main.data

trend_data <- 
norm_data |> 
  mutate(date = as.POSIXct(trend), .before = "pm10") |> 
  openair::TheilSen(pollutant = "pm10", type = ".mod")


```







