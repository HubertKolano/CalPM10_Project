---
title: "Prezentacja_CalPM"
author: "Team2"
abstract-title: "Temat"
abstract: "Zaprezentowanie przebiegu pracy i wyników projektu CalPM"
format: 
  html:
    toc: true
    toc-depth: 3
    toc-location: right
    toc-title: Spis Treści
    number-sections: true
    number-depth: 3
    embed-resources: true
    html-math-method: katex
    code-tools: true
    code-block-bg: true
    code-fold: show
    code-summary: "Show and hide code"
    link-external-icon: true
    link-external-newwindow: true
    smooth-scroll: true
    self-contained: true
    citation: true
    theme: 
        dark: solar
        light: flatly
    fontsize: 1.0em
    linestretch: 1.3
    fig-align: center
execute: 
  echo: true
  error: false
  warning: false
  output: true
---

```{r}
#| echo: false
#| results: "hide"
#| label: Pakiety
pkg <- c(
  "ggthemes",
  "ggplot2",
  "tidyverse",
  "openair",
  "tune"
)

pkg |>
  purrr::map(
    .f = ~ require(.x, character.only = T) |> paste(.x)
  )
rm(pkg)
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
load("plot_data.RData")

wind_set_dir <- function(kat) {
  directions <- c("N", "NNE", "NE", "ENE", "E", "ESE", "SE", "SSE", 
                  "S", "SSW", "SW", "WSW", "W", "WNW", "NW", "NNW")
  index <- floor((kat + 11.25) / 22.5) %% 16 + 1
  
  directions[index]
}

#don't modify the ops file as this is our input we should always derive from
load("ops.RData") ; ops <-
  ops |>
  na.omit() |> 
  select(-ops_pm10, -pres_sea) |> #external requirement to never use ops_pm10
  mutate(wd = wind_set_dir(wd))
  
#validation data (different measurement method)

load("data_test.RData") ; ops_validation <- 
  left_join(ops_data, bam, by = "date")|> 
  select(!grimm_pm10, -(poj_h:hour)) |> 
  relocate(bam_pm10, .before = "n_0044") |> 
  rename(grimm_pm10 = bam_pm10) |> 
  na.omit() |> 
  mutate(wd = wind_set_dir(wd))
```

# Organizacja pracy

Praca była wykonywana w przybliżeniu przebiegała następującego według diagramu blokowego:

![Diagram blokowy przedstawiający workflow](images/mindmap_calpm.png)

Praca rozpoczynała się zawsze od spotkania, omówienia wspólnie obecnego stanu projektu/celu, wyznaczeniu zadań na następny tydzień i zapisaniu ich w Plannerze (appka teams):![Wygląd tablicy pod koniec projektu](images/clipboard-1910004781.png){width="1300"}

Starano się aby każdy na tydzień miał wyznaczone zadanie, które będzie mogło być wykonywane równolegle z resztą zespołu, nie zawsze było to jednak łatwe do osiągnięcia.

Np. przy starcie projektu należało stworzyć pierwszy plik, w którym zostaną wczytane podstawowe biblioteki oraz dane. Gdyby każdy to zrobił z osobna, zostały by zmarnowane zasoby na powtarzanie tej samej czynności i ciężko było by dokonać tego merge. Dlatego niektóre czynności, które musiały być wykonane tylko raz i wstrzymywałyby resztę zespołu przed pracą były przypisywane do osób, które wyrażały możliwość szybkiego wykonania taska.

**Praca w jednym pliku** - celem ćwiczenia, aby lepiej widzieć postępujący kod pisany przez innych i stworzenie merge konfliktów zdecydowano się na pracę w jednym pliku R. Wraz z rozwojem projektu, plik osiągnął 1000+ linijek, co robi się ciężkie do nawigowania po nim.

**Praca z gitem -** po wyznaczeniu tasków, każdy mógł stworzyć od main'a swój branch, na którym mógł bez przeszkód wykonywać zadanie, po uznaniu go za spełniające kryteria, wystawiał pull request, lider robił review, gdzie decydował się na przyłączenie (bądź tez nie, wtedy zostawiał feedback 😉) do main'a. Merge conflicty również były rozwiązywane przez lidera. Po udanym merge lider odhaczał taska w plannerze.

![](images/clipboard-503873801.png)

![](images/clipboard-1210523945.png)

# Wykonywanie projektu

Sam projekt CalPM, został podzielony na części - przygotowanie skryptu, przygotowanie przepisów, przygotowanie i trenowanie modeli, sprawdzenie modeli na rewalidacyjnym zestawie danych i sporządzenie metryk i wykresów.

Kroki wykonywane przy wykonywaniu projektu, wszystko co mogło być robione równolegle jest napisane w jednym kroku.

1.  Stworzenie skryptu z podstawowymi danymi

2.  Utworzenie przykładowego przepisu (umożliwia każdemu tworzenie modelów)

3.  Wytrenowanie wybranych modeli, utworzenie dodatkowych przepisów (najbardziej pracochłonny krok)

4.  Sprawdzenie wszystkich modeli na zestawie walidacyjnym, utworzenie wykresów metryk i tabeli porównawczych modeli.

W skrypcie za pomocą komentarzy wydzielano wspólne i osobne przestrzenie, dla przykładu:

```{r}
#| eval: false
# loading all libraries and files
# List of required packages !!!! please add your libraries to the vector !!!!
required_packages <- c("tidyverse", "data.table", "dplyr",
                       "ggpubr", "ranger", "modeldata", "tidymodels",
                       "rpart.plot", "readr","vip", "ggthemes", 
                       "parsnip", "GGally", "skimr", "xgboost",
                       "doParallel", "kernlab", "ggplot2")  
#

[...]

## XGBoost model ---------------------------------------------------------------

# XGBoost model specification
xgboost_model <- 
  boost_tree(
    mode = "regression",
    trees = 200,
    min_n = tune(),
    tree_depth = tune(),
    learn_rate = tune(),
    loss_reduction = tune()
  ) |> 
  [...]
```

Wszystkie wytrenowane modele (na tym samym seedzie) były zapisywane do pliku, celem uniknięcia ponownego wykonywania czasochłonnych operacji. Zastosowano proste wyrażenie IF/ELSE którym można decydować czy chcemy wykonać cały skrypt trenując modele od nowa

```{r}
#| eval: false
# It is better to load stored data, computation takes too long
if (xgboost_load_data) {
  
  load("xgboost_data.RData")
  
} else {

# Parallel computing 
  cores = detectCores()
  cl = makeCluster(cores)
  registerDoParallel(cl)

# Hyperparameter tuning
  xgboost_tuned_basic <- 
    tune_grid(
    object = xgboost_wf_basic,
    resamples = xgboost_folds,
    grid = xgboost_grid,
    metrics = xgboost_metrics,
    control = control_grid(verbose = TRUE)
)
```

# Lessons Learned

-   Warto lepiej zgłębić temat przed planowaniem pracy - jako lider na początku nie za bardzo rozumiałem scope całego projektu, gdyby to poprawić można by lepiej zaplanować równoległą pracę w projekcie oraz poświęcić więcej czasu na dopracowanie modeli/zwiększenie liczebności.

-   Możliwe ustalenie wszystkich potrzebnych wspólnych konwencji - jaki seed, w jakiej formie każdy powinien przedstawić wydajność swojego modelu, jak nazywać zmienne, aby uniknąć chaosu (team poradził sobie z tym tematem bardzo dobrze, ale myślę że jako lider powinienem to poruszyć).

-   Przekombinowanie plannera - w tak prostym projekcie nie potrzebne jest, aby każdy oznajmiał nad czym obecnie pracuje, a co ma już oddane. Jest to przecież projekt wykonywany w wolnym czasie. Metodologię pracy należy dobierać do potrzeb zespołu.

# Wyniki projektu

Finalnie stworzono 4 modele, których finalne, najlepsze wytrenowane wersje prezentują następujące parametry wydajności oraz odwzorowanie predykcyji na wykresie:

```{r}
#| echo: false
final_metrics
```

Wyjaśnienie przepisów:

-   **GLM** - przepis utworzony specjalnie dla modelu liniowego (przy użyciu metody hellwiga)

-   **HLWG** - przepis w którym metody zostały dobrane przy użyciu metody hellwiga

-   **Upgraded** - przepis utworzony poprzez ręczne badanie korelacji predyktorów i sprawdzanie wagi predyktorów w wytrenowanym modelu.

```{r}
#| echo: false
ggplot(all_results, aes(x = date)) +
  geom_line(aes(y = grimm_pm10, color = "Actual"), size = 1) +
  geom_line(aes(y = .pred, color = "Predicted"), size=0.5) +
  facet_wrap(~ model, scales = "free_y") +
  labs(
    title = "Comparison of Actual and Predicted Values",
    x = "Date",
    y = "PM10 Concentration",
    color = "Values"
  ) +
  theme_minimal() +
  coord_cartesian(ylim = c(0, 75)) +
  scale_color_manual(values = c("Actual" = "green", "Predicted" = "red"))
```

Co prawda najlepszy parametr R^2^ osiąga model GLM, jednak o wiele lepsze parametry RMSE oraz MAE osiągnał model XGBoost, wygląda się też byc lepiej dopasowany na do oryginalnej krzywej, porównując te dwa modele na bardziej szczegółowym wykresie, można zauważyć więcej:

```{r}
#| echo: false
left_join(
  all_results %>%
    filter(model == "GLM") %>%
    select(date, .pred, grimm_pm10) %>%
    na.omit(),
  ops_bam %>% select(date, ops_pm10),
  by = "date"
) %>%
  select(date, grimm_pm10, ops_pm10, .pred) %>%
  rename('Calibration algorithm' = .pred,
         'Correction factor' = ops_pm10) %>%
  pivot_longer('Correction factor':'Calibration algorithm') -> to_p_glm

left_join(
  all_results %>%
    filter(model == "XGBoost") %>%
    select(date, .pred, grimm_pm10) %>%
    na.omit(),
  ops_bam %>% select(date, ops_pm10),
  by = "date"
) %>%
  select(date, grimm_pm10, ops_pm10, .pred) %>%
  rename('Calibration algorithm' = .pred,
         'Correction factor' = ops_pm10) %>%
  pivot_longer('Correction factor':'Calibration algorithm') -> to_p_xboost

to_p_glm %>%
  timeVariation(pollutant = "value",
                group = "name", 
                ylab ="Concentration PM10 [ug/m3]",
                main = "GLM") -> p_tv_glm

to_p_xboost %>%
  timeVariation(pollutant = "value",
                group = "name", 
                ylab ="Concentration PM10 [ug/m3]",
                main = "XGBoost") -> p_tv_xgboost

```

Porównując obydwa wykresy widzimy, że chociaż faktycznie GLM predyktujema wartośc bliższą właściwej, to XGBoost generuje prawie identyczny kształt krzywej, tylko liniowo przesuniętej. Ten powód kategoryzuje XGBoost jako lepszy model.

```{r}
#| echo: false
to_p_xboost %>% 
  timeAverage(avg.time = "day", 
              type = "name") %>% 
  filter(value < 150) %>% 
  ggplot(aes(grimm_pm10, value)) +
  geom_point() +
  facet_wrap(~name) + 
  geom_abline(slope = c(1.5, 0.5, 1),
              col = rep(c("blue", "blue",
                          "red"),
                        2)) +
  theme_bw() +
  scale_x_continuous(limits = c(0,60), expand = c(0,0)) + 
  scale_y_continuous(limits = c(0,60), expand = c(0,0)) +
  coord_obs_pred() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(
    x =  expression("Concentration PM"[10] *
                      " [" * mu * "g m" ^ -3 * "] - BAM-1020") ,
    y = expression("Concentration PM"[10] *
                     " [" * mu * "g m" ^ -3 * "] - OPS 3330")
  )
```
